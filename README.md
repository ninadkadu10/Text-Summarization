# Text-Summarization
Text summarization is a natural language processing task that aims to condense 
a given text into a shorter version while preserving its key information and main 
ideas. There are two main approaches to text summarization: extractive and 
abstractive. 
Extractive Summarization: 
Extractive summarization involves selecting and rearranging the most important 
sentences or phrases from the original text to create a summary. 
It relies on techniques such as sentence scoring, ranking, and clustering to 
identify the most relevant sentences. 
Extractive summarization methods are relatively simpler and computationally 
less expensive compared to abstractive methods. 
However, the summaries generated by extractive approaches can sometimes 
lack coherence and fluency. 
Abstractive Summarization: 
Abstractive summarization aims to generate a summary that goes beyond the 
original text by understanding and expressing the underlying meaning. 
It involves techniques such as natural language understanding, semantic 
representation, and language generation. 
Abstractive methods use advanced machine learning techniques, including deep 
learning and neural networks, to generate summaries that can be more coherent 
and fluent. 
However, abstractive summarization is a more challenging task due to the need 
for semantic understanding and language generation capabilities. 
Evaluation of text summarization systems: 
Evaluating the quality of summarization systems is subjective and often 
involves human judgment. 
Common evaluation metrics include ROUGE (Recall-Oriented Understudy for 
Gisting Evaluation), which measures the overlap between the system-generated 
summary and human-created reference summaries. 
Other metrics such as BLEU (Bilingual Evaluation Understudy) and METEOR 
(Metric for Evaluation of Translation with Explicit ORdering) are also used in 
some cases. 
Applications of text summarization: 
Text summarization has various practical applications, such as news 
summarization, document summarization, and social media summarization. 
It can help in quickly understanding the main points of a lengthy document or 
article, enabling efficient information retrieval and decision-making. 
Text summarization also finds applications in automatic document 
categorization, information retrieval systems, and chatbot systems. 
In summary, text summarization is an important NLP task that aims to generate 
concise and informative summaries from given texts. Extractive and abstractive 
approaches are commonly used, each with its strengths and limitations. 
Evaluation of summarization systems relies on metrics like ROUGE, while 
applications range from news and document summarization to information 
retrieval and chatbot systems. 
Text-Summarization App using NLTK, Spacy using Streamlit
SPACY: Spacy is an open-source software python library used in advanced 
natural language processing and machine learning. It will be used to build 
information extraction, natural language understanding systems, and to preprocess text for deep learning. It supports deep learning workflow in 
convolutional neural networks in parts-of-speech tagging, dependency parsing, 
and named entity recognition. 
Installation: pip3 install spacy 
NLTK: NLTK stands for Natural Language Toolkit.The Natural Language 
Toolkit (NLTK) is a platform used for building Python programs that work with 
human language data for applying in statistical natural language processing 
(NLP).It contains text processing libraries for tokenization, parsing, 
classification, stemming, tagging and semantic reasoning. 
Installation: pip3 install nltk 
NLP: It is the ability of a computer program to understand human language as it 
is spoken and written referred to as natural language. It is a component of 
artificial intelligence(AI). 
There are two main phases to natural language processing: 
1.data preprocessing 
2.algorithm development 
Streamlit: It is an open-source Python library that makes it easy to create and 
share beautiful, custom web apps for machine learning and data science. In just 
a few minutes you can build and deploy powerful data apps
